{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlRqbJWouSUA",
        "outputId": "027863cd-995d-40e1-b824-e9ccf5982bb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.247-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymupdf\n",
            "  Downloading PyMuPDF-1.22.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unstructured\n",
            "  Downloading unstructured-0.8.7-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb\n",
            "  Downloading chromadb-0.4.3-py3-none-any.whl (399 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.0/399.0 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.13-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.11 (from langchain)\n",
            "  Downloading langsmith-0.0.15-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.11.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.0.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.3)\n",
            "Collecting msg-parser (from unstructured)\n",
            "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.0.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.5.3)\n",
            "Collecting pdf2image (from unstructured)\n",
            "  Downloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
            "Collecting pdfminer.six (from unstructured)\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unstructured) (9.4.0)\n",
            "Collecting pypandoc (from unstructured)\n",
            "  Downloading pypandoc-1.11-py3-none-any.whl (20 kB)\n",
            "Collecting python-docx (from unstructured)\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-pptx (from unstructured)\n",
            "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.4.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chroma-hnswlib==0.7.1 (from chromadb)\n",
            "  Downloading chroma-hnswlib-0.7.1.tar.gz (30 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fastapi<0.100.0,>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.23.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.7.1)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.3.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi<0.100.0,>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.6)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.4.1)\n",
            "Collecting olefile>=0.46 (from msg-parser->unstructured)\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.3.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured) (1.1.0)\n",
            "Collecting cryptography>=36.0.0 (from pdfminer.six->unstructured)\n",
            "  Downloading cryptography-41.0.2-cp37-abi3-manylinux_2_28_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting XlsxWriter>=0.5.7 (from python-pptx->unstructured)\n",
            "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.15.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.1.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.21)\n",
            "Building wheels for collected packages: wikipedia, chroma-hnswlib, pypika, python-docx, python-pptx, olefile\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=9321553a2b1d43caa17b770d4e8ea7634846d0ab3bbec1cec4008efc066857e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chroma-hnswlib: filename=chroma_hnswlib-0.7.1-cp310-cp310-linux_x86_64.whl size=2273167 sha256=83d863adf8b36c9160cc5eaf2ce09e50e16e3866c415ef3f248e9efeb09429e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/f2/d2/3f32228e9f4713a9f32a468de8bbc3c642f7805ebef888418b\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=20b7929c2e2a6c8f2d7113e7e87c9305ed8ccfe5a8e21745e90b04c3ce0d4079\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184489 sha256=c4e4747b260abdcddd185db015d3ef6075b1264fb9348455a4f99f90258834cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470934 sha256=fa26724ac71286b82f622719fa110f9ca37b851d94d64156524438f20f1f6f06\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/dd/74/01b3ec7256a0800b99384e9a0f7620e358afc3a51a59bf9b49\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35414 sha256=6df7744bd655e818b38b2ec58a805987b9130898d38dd403e1190e95816cf0a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
            "Successfully built wikipedia chroma-hnswlib pypika python-docx python-pptx olefile\n",
            "Installing collected packages: tokenizers, pypika, monotonic, filetype, XlsxWriter, websockets, uvloop, requests, python-magic, python-dotenv, python-docx, pypandoc, pymupdf, pulsar-client, pdf2image, overrides, olefile, mypy-extensions, marshmallow, humanfriendly, httptools, h11, chroma-hnswlib, backoff, wikipedia, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, python-pptx, posthog, openapi-schema-pydantic, msg-parser, langsmith, cryptography, coloredlogs, pdfminer.six, openai, onnxruntime, fastapi, dataclasses-json, unstructured, langchain, chromadb\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 3.4.8\n",
            "    Uninstalling cryptography-3.4.8:\n",
            "      Successfully uninstalled cryptography-3.4.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed XlsxWriter-3.1.2 backoff-2.2.1 chroma-hnswlib-0.7.1 chromadb-0.4.3 coloredlogs-15.0.1 cryptography-41.0.2 dataclasses-json-0.5.13 fastapi-0.99.1 filetype-1.2.0 h11-0.14.0 httptools-0.6.0 humanfriendly-10.0 langchain-0.0.247 langsmith-0.0.15 marshmallow-3.20.1 monotonic-1.6 msg-parser-1.2.0 mypy-extensions-1.0.0 olefile-0.46 onnxruntime-1.15.1 openai-0.27.8 openapi-schema-pydantic-1.2.4 overrides-7.3.1 pdf2image-1.16.3 pdfminer.six-20221105 posthog-3.0.1 pulsar-client-3.2.0 pymupdf-1.22.5 pypandoc-1.11 pypika-0.48.9 python-docx-0.8.11 python-dotenv-1.0.0 python-magic-0.4.27 python-pptx-0.6.21 requests-2.31.0 starlette-0.27.0 tiktoken-0.4.0 tokenizers-0.13.3 typing-inspect-0.9.0 unstructured-0.8.7 uvicorn-0.23.1 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3 wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain tiktoken pymupdf wikipedia unstructured openai chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AkpOFJMO96Eb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import date, datetime\n",
        "import json\n",
        "import sys\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.memory import ConversationSummaryBufferMemory, ConversationBufferMemory\n",
        "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.document_loaders import WikipediaLoader, DirectoryLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-BtqRJfJ_6nW"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = \"yourownkey\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obwOiwoG9jsb",
        "outputId": "4a1a19ea-0f7b-4f62-ab51-914b530b5db5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# docsLoader = WikipediaLoader(query=\"Tamarin\", load_max_docs=2).load()\n",
        "# len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Nh75p1piupaP"
      },
      "outputs": [],
      "source": [
        "wikiLoader = WikipediaLoader(query=\"Tamarin\", load_max_docs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_Os4U_7_Dog",
        "outputId": "87d2e9c4-d184-4182-f20e-8f063de0c8f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘Docs’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir Docs # Will create folder \"Docs\" if not exist\n",
        "docsLoader = DirectoryLoader(\"Docs/\") # Put PDFs here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyYeqd6owYlk"
      },
      "outputs": [],
      "source": [
        "# Load all documents into vector storage\n",
        "index = VectorstoreIndexCreator().from_loaders([docsLoader,wikiLoader])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "VTfQTA2UkK7J"
      },
      "outputs": [],
      "source": [
        "def generate_template():\n",
        "    \"\"\"\n",
        "    Custom prompt for bot instruction.\n",
        "    \"\"\"\n",
        "\n",
        "    template =  \"\"\"Please answer based on context below (delimited by triple backticks)\n",
        "    If the question does not relate to any of the context, just say that you don't know the answer.\n",
        "    Please answer in English\n",
        "    ```\n",
        "    {context}\n",
        "    ```\"\"\"\n",
        "\n",
        "    general_user_template = \"Question:```{question}```\"\n",
        "    general_system_template  = template\n",
        "    messages = [\n",
        "            SystemMessagePromptTemplate.from_template(general_system_template),\n",
        "            HumanMessagePromptTemplate.from_template(general_user_template)\n",
        "    ]\n",
        "    qa_prompt = ChatPromptTemplate.from_messages(messages)\n",
        "    return qa_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "lxvmetUwi-H7"
      },
      "outputs": [],
      "source": [
        "# Define object for LLM, Memory, & Retriever\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0613\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=3800, memory_key=\"chat_history\", return_messages=True)\n",
        "retriever = index.vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "w-DV2cTVpKb4"
      },
      "outputs": [],
      "source": [
        "# Csutom prompt template for condense_question_prompt. Just omit condense_question_prompt parameter from chain if not using custom prompt.\n",
        "template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in English language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:'\n",
        "condense_question_prompt = PromptTemplate(input_variables=['chat_history', 'question'],\n",
        "                                          output_parser=None,\n",
        "                                          partial_variables={},\n",
        "                                          template=template,\n",
        "                                          template_format='f-string',\n",
        "                                          validate_template=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "pyhySq42IYQI"
      },
      "outputs": [],
      "source": [
        "# Define chain object for Conversational Retrival Chain\n",
        "chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=False,\n",
        "        return_generated_question=False,\n",
        "        memory=memory,\n",
        "        condense_question_prompt=condense_question_prompt,\n",
        "        combine_docs_chain_kwargs={\"prompt\": generate_template()},\n",
        "        verbose=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zFMDhqSc_3Gl",
        "outputId": "65688c51-637c-450b-a9e0-30cbca6298dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: tell me about tamarin\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Please answer based on context below (delimited by triple backticks)\n",
            "    If the question does not relate to any of the context, just say that you don't know the answer. \n",
            "    Please answer in English\n",
            "    ```\n",
            "    == Behavior and reproduction ==\n",
            "Tamarins are inhabitants of tropical rainforests and open forest areas. They are diurnal and arboreal, and run and jump quickly through the trees. Tamarins live together in groups of up to 40 members consisting of one or more families. More frequently, though, groups are composed of just three to nine members.\n",
            "Tamarins are omnivores, eating fruits and ot\n",
            "\n",
            "== Behavior and reproduction ==\n",
            "Tamarins are inhabitants of tropical rainforests and open forest areas. They are diurnal and arboreal, and run and jump quickly through the trees. Tamarins live together in groups of up to 40 members consisting of one or more families. More frequently, though, groups are composed of just three to nine members.\n",
            "Tamarins are omnivores, eating fruits and ot\n",
            "\n",
            "The cotton-top tamarin (Saguinus oedipus) is a small New World monkey weighing less than 0.5 kg (1.1 lb). This New World monkey can live up to 24 years, but most of them die by 13 years. One of the smallest primates, the cotton-top tamarin is easily recognized by the long, white sagittal crest extending from its forehead to its shoulders. The species is found in tropical forest edges and secondary forests in northwestern Colombia, where it is arboreal and diurnal. Its diet includes insects and plant exudates, and it is an important seed disperser in the tropical ecosystem.\n",
            "\n",
            "== Description ==\n",
            "Tamarin species vary considerably in appearance, ranging from nearly all black through mixtures of black, brown and white.  Mustache-like facial hairs are typical for many species. Their body size ranges from 13 to 30 cm (5.1 to 11.8 in) (plus a 25-to-44 cm-long (9.8-to-17.3 in) tail). They weigh from 348 to 575 grams (12.3 to 20.3 oz). In captivity, red-bellied tamarins have been recorded living up to 20.5 years, while cotton-top tamarins can live up to 23 years old.\n",
            "\n",
            "\n",
            "== Distribution ==\n",
            "Tamarins range from southern Central America through central South America, where they are found in northwestern Colombia, the Amazon basin, and the Guianas.\n",
            "\n",
            "== Description ==\n",
            "Tamarin species vary considerably in appearance, ranging from nearly all black through mixtures of black, brown and white.  Mustache-like facial hairs are typical for many species. Their body size ranges from 13 to 30 cm (5.1 to 11.8 in) (plus a 25-to-44 cm-long (9.8-to-17.3 in) tail). They weigh from 348 to 575 grams (12.3 to 20.3 oz). In captivity, red-bellied tamarins have been recorded living up to 20.5 years, while cotton-top tamarins can live up to 23 years old.\n",
            "\n",
            "\n",
            "== Distribution ==\n",
            "Tamarins range from southern Central America through central South America, where they are found in northwestern Colombia, the Amazon basin, and the Guianas.\n",
            "    ```\n",
            "Human: Question:```tell me about tamarin```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Tamarins are small New World monkeys that inhabit tropical rainforests and open forest areas. They are diurnal and arboreal, meaning they are active during the day and spend most of their time in trees. Tamarins are known for their agility and can run and jump quickly through the trees.\n",
            "\n",
            "They live together in groups called troops, which can consist of up to 40 members. These troops are usually made up of one or more families, but more commonly have three to nine members. Tamarins are omnivores, meaning they eat both fruits and other foods like insects and plant exudates.\n",
            "\n",
            "There are different species of tamarins, and they vary in appearance. They can range from nearly all black to mixtures of black, brown, and white. Many species have mustache-like facial hairs. Tamarins have a body size ranging from 13 to 30 cm (5.1 to 11.8 in) and weigh between 348 to 575 grams (12.3 to 20.3 oz). They have a long tail, which can be 25 to 44 cm (9.8 to 17.3 in) long.\n",
            "\n",
            "The cotton-top tamarin is one specific species of tamarin. It is easily recognized by the long, white sagittal crest extending from its forehead to its shoulders. It is found in tropical forest edges and secondary forests in northwestern Colombia. The cotton-top tamarin is an important seed disperser in the tropical ecosystem and has a diet that includes insects and plant exudates.\n",
            "\n",
            "Tamarins have a lifespan of up to 24 years, but most of them die by 13 years. In captivity, red-bellied tamarins have been recorded living up to 20.5 years, while cotton-top tamarins can live up to 23 years old. Tamarins range from southern Central America through central South America, including northwestern Colombia, the Amazon basin, and the Guianas.\n",
            "Prompt: what is machine learning?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in English language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: tell me about tamarin\n",
            "Assistant: Tamarins are small New World monkeys that inhabit tropical rainforests and open forest areas. They are diurnal and arboreal, meaning they are active during the day and spend most of their time in trees. Tamarins are known for their agility and can run and jump quickly through the trees.\n",
            "\n",
            "They live together in groups called troops, which can consist of up to 40 members. These troops are usually made up of one or more families, but more commonly have three to nine members. Tamarins are omnivores, meaning they eat both fruits and other foods like insects and plant exudates.\n",
            "\n",
            "There are different species of tamarins, and they vary in appearance. They can range from nearly all black to mixtures of black, brown, and white. Many species have mustache-like facial hairs. Tamarins have a body size ranging from 13 to 30 cm (5.1 to 11.8 in) and weigh between 348 to 575 grams (12.3 to 20.3 oz). They have a long tail, which can be 25 to 44 cm (9.8 to 17.3 in) long.\n",
            "\n",
            "The cotton-top tamarin is one specific species of tamarin. It is easily recognized by the long, white sagittal crest extending from its forehead to its shoulders. It is found in tropical forest edges and secondary forests in northwestern Colombia. The cotton-top tamarin is an important seed disperser in the tropical ecosystem and has a diet that includes insects and plant exudates.\n",
            "\n",
            "Tamarins have a lifespan of up to 24 years, but most of them die by 13 years. In captivity, red-bellied tamarins have been recorded living up to 20.5 years, while cotton-top tamarins can live up to 23 years old. Tamarins range from southern Central America through central South America, including northwestern Colombia, the Amazon basin, and the Guianas.\n",
            "Follow Up Input: what is machine learning?\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Please answer based on context below (delimited by triple backticks)\n",
            "    If the question does not relate to any of the context, just say that you don't know the answer. \n",
            "    Please answer in English\n",
            "    ```\n",
            "    1. Machine learning is at the core of many recent advances in science and technology. Unfortunately, the important role of humans is an oft-overlooked aspect in the ﬁeld. Whether humans are directly using machine learning classiﬁers as tools, or are deploying models within other products, a vital concern remains: if the users do not trust a model or a prediction, they will not use it. It is important to diﬀerentiate between two diﬀerent (but related) deﬁnitions of trust: (1) trusting a prediction, i.e. whether a user trusts an individual prediction suﬃciently to take some action based on it, and (2) trusting a model, i.e. whether the user trusts a model to behave in reasonable ways if deployed. Both are directly impacted by\n",
            "\n",
            "INTRODUCTION\n",
            "\n",
            "SP-LIME, a method that selects a set of representative instances with explanations to address the “trusting the model” problem, via submodular optimization.\n",
            "\n",
            "1. Machine learning is at the core of many recent advances in science and technology. Unfortunately, the important role of humans is an oft-overlooked aspect in the ﬁeld. Whether humans are directly using machine learning classiﬁers as tools, or are deploying models within other products, a vital concern remains: if the users do not trust a model or a prediction, they will not use it. It is important to diﬀerentiate between two diﬀerent (but related) deﬁnitions of trust: (1) trusting a prediction, i.e. whether a user trusts an individual prediction suﬃciently to take some action based on it, and (2) trusting a model, i.e. whether the user trusts a model to behave in reasonable ways if deployed. Both are directly impacted by\n",
            "\n",
            "INTRODUCTION\n",
            "\n",
            "SP-LIME, a method that selects a set of representative instances with explanations to address the “trusting the model” problem, via submodular optimization.\n",
            "\n",
            "1. Machine learning is at the core of many recent advances in science and technology. Unfortunately, the important role of humans is an oft-overlooked aspect in the ﬁeld. Whether humans are directly using machine learning classiﬁers as tools, or are deploying models within other products, a vital concern remains: if the users do not trust a model or a prediction, they will not use it. It is important to diﬀerentiate between two diﬀerent (but related) deﬁnitions of trust: (1) trusting a prediction, i.e. whether a user trusts an individual prediction suﬃciently to take some action based on it, and (2) trusting a model, i.e. whether the user trusts a model to behave in reasonable ways if deployed. Both are directly impacted by\n",
            "\n",
            "INTRODUCTION\n",
            "\n",
            "SP-LIME, a method that selects a set of representative instances with explanations to address the “trusting the model” problem, via submodular optimization.\n",
            "\n",
            "1. Machine learning is at the core of many recent advances in science and technology. Unfortunately, the important role of humans is an oft-overlooked aspect in the ﬁeld. Whether humans are directly using machine learning classiﬁers as tools, or are deploying models within other products, a vital concern remains: if the users do not trust a model or a prediction, they will not use it. It is important to diﬀerentiate between two diﬀerent (but related) deﬁnitions of trust: (1) trusting a prediction, i.e. whether a user trusts an individual prediction suﬃciently to take some action based on it, and (2) trusting a model, i.e. whether the user trusts a model to behave in reasonable ways if deployed. Both are directly impacted by\n",
            "\n",
            "INTRODUCTION\n",
            "\n",
            "SP-LIME, a method that selects a set of representative instances with explanations to address the “trusting the model” problem, via submodular optimization.\n",
            "\n",
            "1. Machine learning is at the core of many recent advances in science and technology. Unfortunately, the important role of humans is an oft-overlooked aspect in the ﬁeld. Whether humans are directly using machine learning classiﬁers as tools, or are deploying models within other products, a vital concern remains: if the users do not trust a model or a prediction, they will not use it. It is important to diﬀerentiate between two diﬀerent (but related) deﬁnitions of trust: (1) trusting a prediction, i.e. whether a user trusts an individual prediction suﬃciently to take some action based on it, and (2) trusting a model, i.e. whether the user trusts a model to behave in reasonable ways if deployed. Both are directly impacted by\n",
            "\n",
            "INTRODUCTION\n",
            "\n",
            "SP-LIME, a method that selects a set of representative instances with explanations to address the “trusting the model” problem, via submodular optimization.\n",
            "    ```\n",
            "Human: Question:```What is the definition of machine learning?```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Machine learning is a field of study and practice that involves the development of algorithms and models that enable computers to learn and make predictions or decisions without being explicitly programmed. It is a subset of artificial intelligence that focuses on the development of systems that can learn from data and improve their performance over time.\n",
            "Prompt: what is human role in machine learning\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in English language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: tell me about tamarin\n",
            "Assistant: Tamarins are small New World monkeys that inhabit tropical rainforests and open forest areas. They are diurnal and arboreal, meaning they are active during the day and spend most of their time in trees. Tamarins are known for their agility and can run and jump quickly through the trees.\n",
            "\n",
            "They live together in groups called troops, which can consist of up to 40 members. These troops are usually made up of one or more families, but more commonly have three to nine members. Tamarins are omnivores, meaning they eat both fruits and other foods like insects and plant exudates.\n",
            "\n",
            "There are different species of tamarins, and they vary in appearance. They can range from nearly all black to mixtures of black, brown, and white. Many species have mustache-like facial hairs. Tamarins have a body size ranging from 13 to 30 cm (5.1 to 11.8 in) and weigh between 348 to 575 grams (12.3 to 20.3 oz). They have a long tail, which can be 25 to 44 cm (9.8 to 17.3 in) long.\n",
            "\n",
            "The cotton-top tamarin is one specific species of tamarin. It is easily recognized by the long, white sagittal crest extending from its forehead to its shoulders. It is found in tropical forest edges and secondary forests in northwestern Colombia. The cotton-top tamarin is an important seed disperser in the tropical ecosystem and has a diet that includes insects and plant exudates.\n",
            "\n",
            "Tamarins have a lifespan of up to 24 years, but most of them die by 13 years. In captivity, red-bellied tamarins have been recorded living up to 20.5 years, while cotton-top tamarins can live up to 23 years old. Tamarins range from southern Central America through central South America, including northwestern Colombia, the Amazon basin, and the Guianas.\n",
            "Human: what is machine learning?\n",
            "Assistant: Machine learning is a field of study and practice that involves the development of algorithms and models that enable computers to learn and make predictions or decisions without being explicitly programmed. It is a subset of artificial intelligence that focuses on the development of systems that can learn from data and improve their performance over time.\n",
            "Follow Up Input: what is human role in machine learning\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: Please answer based on context below (delimited by triple backticks)\n",
            "    If the question does not relate to any of the context, just say that you don't know the answer. \n",
            "    Please answer in English\n",
            "    ```\n",
            "    1. Machine learning is at the core of many recent advances in science and technology. Unfortunately, the important role of humans is an oft-overlooked aspect in the ﬁeld. Whether humans are directly using machine learning classiﬁers as tools, or are deploying models within other products, a vital concern remains: if the users do not trust a model or a prediction, they will not use it. It is important to diﬀerentiate between two diﬀerent (but related) deﬁnitions of trust: (1) trusting a prediction, i.e. whether a user trusts an individual prediction suﬃciently to take some action based on it, and (2) trusting a model, i.e. whether the user trusts a model to behave in reasonable ways if deployed. Both are directly impacted by\n",
            "\n",
            "INTRODUCTION\n",
            "\n",
            "SP-LIME, a method that selects a set of representative instances with explanations to address the “trusting the model” problem, via submodular optimization.\n",
            "\n",
            "1. Machine learning is at the core of many recent advances in science and technology. Unfortunately, the important role of humans is an oft-overlooked aspect in the ﬁeld. Whether humans are directly using machine learning classiﬁers as tools, or are deploying models within other products, a vital concern remains: if the users do not trust a model or a prediction, they will not use it. It is important to diﬀerentiate between two diﬀerent (but related) deﬁnitions of trust: (1) trusting a prediction, i.e. whether a user trusts an individual prediction suﬃciently to take some action based on it, and (2) trusting a model, i.e. whether the user trusts a model to behave in reasonable ways if deployed. Both are directly impacted by\n",
            "\n",
            "INTRODUCTION\n",
            "\n",
            "SP-LIME, a method that selects a set of representative instances with explanations to address the “trusting the model” problem, via submodular optimization.\n",
            "\n",
            "1. Machine learning is at the core of many recent advances in science and technology. Unfortunately, the important role of humans is an oft-overlooked aspect in the ﬁeld. Whether humans are directly using machine learning classiﬁers as tools, or are deploying models within other products, a vital concern remains: if the users do not trust a model or a prediction, they will not use it. It is important to diﬀerentiate between two diﬀerent (but related) deﬁnitions of trust: (1) trusting a prediction, i.e. whether a user trusts an individual prediction suﬃciently to take some action based on it, and (2) trusting a model, i.e. whether the user trusts a model to behave in reasonable ways if deployed. Both are directly impacted by\n",
            "\n",
            "INTRODUCTION\n",
            "\n",
            "SP-LIME, a method that selects a set of representative instances with explanations to address the “trusting the model” problem, via submodular optimization.\n",
            "\n",
            "1. Machine learning is at the core of many recent advances in science and technology. Unfortunately, the important role of humans is an oft-overlooked aspect in the ﬁeld. Whether humans are directly using machine learning classiﬁers as tools, or are deploying models within other products, a vital concern remains: if the users do not trust a model or a prediction, they will not use it. It is important to diﬀerentiate between two diﬀerent (but related) deﬁnitions of trust: (1) trusting a prediction, i.e. whether a user trusts an individual prediction suﬃciently to take some action based on it, and (2) trusting a model, i.e. whether the user trusts a model to behave in reasonable ways if deployed. Both are directly impacted by\n",
            "\n",
            "INTRODUCTION\n",
            "\n",
            "SP-LIME, a method that selects a set of representative instances with explanations to address the “trusting the model” problem, via submodular optimization.\n",
            "\n",
            "1. Machine learning is at the core of many recent advances in science and technology. Unfortunately, the important role of humans is an oft-overlooked aspect in the ﬁeld. Whether humans are directly using machine learning classiﬁers as tools, or are deploying models within other products, a vital concern remains: if the users do not trust a model or a prediction, they will not use it. It is important to diﬀerentiate between two diﬀerent (but related) deﬁnitions of trust: (1) trusting a prediction, i.e. whether a user trusts an individual prediction suﬃciently to take some action based on it, and (2) trusting a model, i.e. whether the user trusts a model to behave in reasonable ways if deployed. Both are directly impacted by\n",
            "\n",
            "INTRODUCTION\n",
            "\n",
            "SP-LIME, a method that selects a set of representative instances with explanations to address the “trusting the model” problem, via submodular optimization.\n",
            "    ```\n",
            "Human: Question:```What is the role of humans in machine learning?```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The role of humans in machine learning is important but often overlooked. Humans can directly use machine learning classifiers as tools or deploy models within other products. If users do not trust a model or a prediction, they will not use it. Trust plays a crucial role in machine learning, and it is important for users to trust both individual predictions and the behavior of the model when deployed.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-d66f7e1f084c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Start the conversation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prompt: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# Start the conversation\n",
        "while True:\n",
        "  query = input(\"Prompt: \")\n",
        "  if query in ['quit', 'q', 'exit']:\n",
        "    sys.exit()\n",
        "  result = chain({\"question\": query})\n",
        "  print(result['answer'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
